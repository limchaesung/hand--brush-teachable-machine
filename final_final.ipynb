{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b9eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 585ms/step\n",
      "0\n",
      "hand on\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "0\n",
      "hand on\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0\n",
      "hand on\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2\n",
      "brush\n",
      "[[9.6528686e-04 2.9091738e-04 9.9874383e-01]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2\n",
      "brush\n",
      "[[2.7018550e-04 1.0993941e-04 9.9961984e-01]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2\n",
      "brush\n",
      "[[0.1690793  0.02440089 0.80651975]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "0\n",
      "hand on\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4480\\3361733224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 모델 위치\n",
    "model_filename ='C:\\\\Users\\\\Administrator\\\\keras_model.h5'\n",
    "\n",
    "# 케라스 모델 가져오기\n",
    "model = tensorflow.keras.models.load_model(model_filename)\n",
    "\n",
    "# 카메라를 제어할 수 있는 객체\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# 카메라 길이 너비 조절\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "# 이미지 처리하기\n",
    "def preprocessing(frame):\n",
    "    #frame_fliped = cv2.flip(frame, 1)\n",
    "    # 사이즈 조정 티쳐블 머신에서 사용한 이미지 사이즈로 변경해준다.\n",
    "    size = (224, 224)\n",
    "    frame_resized = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # 이미지 정규화\n",
    "    # astype : 속성\n",
    "    frame_normalized = (frame_resized.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "    # 이미지 차원 재조정 - 예측을 위해 reshape 해줍니다.\n",
    "    # keras 모델에 공급할 올바른 모양의 배열 생성\n",
    "    frame_reshaped = frame_normalized.reshape((1, 224, 224, 3))\n",
    "    #print(frame_reshaped)\n",
    "    return frame_reshaped\n",
    "\n",
    "# 예측용 함수\n",
    "def predict(frame):\n",
    "    prediction = model.predict(frame)\n",
    "    return prediction\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if cv2.waitKey(100) > 0: \n",
    "        break\n",
    "\n",
    "    preprocessed = preprocessing(frame)\n",
    "    prediction = predict(preprocessed)\n",
    "    maxind = np.argmax(prediction)\n",
    "    print(maxind)\n",
    "\n",
    "#     if (prediction[0,0] < prediction[0,1]):\n",
    "    if maxind == 2:\n",
    "        print('brush')\n",
    "        print(prediction)\n",
    "        cv2.putText(frame, 'brush', (0, 25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0))\n",
    "        \n",
    "        cap = cv2.VideoCapture('C:\\\\Users\\\\Administrator\\\\brush.mp4') # mp4 파일\n",
    "        \n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            cv2.imshow('result', img)\n",
    "            if cv2.waitKey(40) == ord('q'):\n",
    "                break\n",
    "        cap.release() # 동영상 파일 닫고 메모리 해제\n",
    "        \n",
    "    elif maxind == 1:\n",
    "        cv2.putText(frame, 'X', (0, 25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0))\n",
    "        print('X')\n",
    "        \n",
    "    elif maxind == 0:\n",
    "        cv2.putText(frame, 'hand on', (0, 25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0))\n",
    "        print('hand on')\n",
    "        \n",
    "        cap = cv2.VideoCapture('C:\\\\Users\\\\Administrator\\\\hand.mp4')\n",
    "        \n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            cv2.imshow('result', img)\n",
    "            if cv2.waitKey(20) == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "    \n",
    "    \n",
    "\n",
    "    cv2.imshow(\"VideoFrame\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eab5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b01c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
